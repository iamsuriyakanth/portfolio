export const portfolioData = {
  hero: {
    badge: "Differentiate or Die",
    name: "Suriyakanth R",
    title: "AI & Data Science Professional",
    tagline: "Specialized in Generative AI & Agentic Systems",
    description: "I build intelligent, scalable AI agent systems, backend infrastructures, and enterprise integrations that deliver real business impact.",
    resumeLink: "https://github.com/iamsuriyakanth/portfolio/blob/main/suriyakanth-resume.pdf?raw=true",
    socialLinks: {
     github: "https://github.com/iamsuriyakanth",
     linkedin: "https://www.linkedin.com/in/suriyakanth2711/",
     twitter: "https://x.com/Suriyakanth2711",
     facebook: "https://www.facebook.com/iamsuriyakanth",
     instagram: "https://www.instagram.com/iamsuriyakanth"
    }
  },
  about: {
    description: "I’m a next-gen technology professional focused on building intelligent systems that bridge research, engineering, and real-world impact. My work centers on evolving AI from a tool that assists to a partner that executes — creating scalable, adaptable, and future-ready solutions."
  },
  techStack: {
    coreSkills: [
      "LLMs & NLP",
      "RAG Systems",
      "Agent Architectures",
      "API Integrations",
      "Webhooks",
      "Data Engineering",
      "Data Pipelines",
      "Analytics",
    ],
    languages: [
      "Python",
      "SQL",
      "TypeScript",
      "JavaScript",
      "C++",
      "R"
    ],
    tools: [
      "OpenAI",
      "AWS",
      "Vertex AI",
      "GitHub",
      "Stripe",
      "Jenkins",
      "Tableau"
    ],
    frameworks: [
      "Flask",
      "FastAPI",
      "PyTorch",
      "TensorFlow",
      "Scikit-learn"
    ]
  },
  projects: [
      {
    "id": 1,
    "title": "OptimBasket",
    "description": "A Python-based portfolio optimization tool that uses Principal Component Analysis (PCA) to construct diversified and risk-optimized stock baskets. Implements algorithmic weight allocation to minimize exposure while maximizing variance reduction. Designed as a lightweight, data-driven assistant for retail and quantitative investors.",
    "tags": [
      "PCA",
      "Portfolio Optimization",
      "Risk Modeling"
    ],
    "link": "https://github.com/iamsuriyakanth/stockPrediction-strategyBuilding-portfolioConstruction"
  },
    {
    "id": 2,
    "title": "Manifesto AI",
    "description": "AI-powered tool that ingests lengthy political manifestos and converts them into concise, citizen-friendly summaries. Uses LLM-driven retrieval and compression techniques to extract key policy points, compare party positions, and provide easy-to-understand breakdowns for informed voting.",
    "tags": [
      "LLMs",
      "RAG",
      "Political Analysis",
      "AI for Social Good"
    ],
    "link": "https://github.com/iamsuriyakanth/manifesto-lens"
  },

  ],
  education: [
    {
      id: 1,
      period: "2019 - 2024",
      degree: "Masters in Data Science",
      institution: "PSG College of Technology",
      location: "Coimbatore, Tamil Nadu, India",
      description: "Focused on Artificial Intelligence, Statistics, Stochastic Processes, Computational Finance, Machine Learning, and Data Science.",
      achievements: [
        "GPA: 8.67/10",
        "Graduated with First Class with Distinction.",
      ]
    },
    {
      id: 2,
      period: "2017 - 2019",
      degree: "Higher Secondary Education",
      institution: "Sathya Vidyalaya",
      location: "Rajapalayam, Tamil Nadu, India",
      description: "Specialized in Biology and Mathematics.",
      achievements: [
      ]
    }
  ],
  experience: [
  {
    "id": 1,
    "period": "June 2024 - Present",
    "isCurrent": true,
    "position": "Member Technical Staff",
    "company": "Haiva Inc",
    "location": "Chennai, Tamil Nadu, India",
    "description": "Founding engineer contributing to the core Adaptive AI Agent platform. Built scalable backend systems, agentic layers, and multi-modal LLM pipelines powering enterprise-grade automations. Delivered plug-and-play integrations, real-time webhook infrastructure, and implemented Microsoft Marketplace onboarding with Azure Metering integration. Built credit-based and subscription-based monetization systems alongside iOS in-app monetization flows. Developed a universal parser optimized for LLM processing and created reusable agent-template pipelines enabling rapid configuration and deployment of customer-ready AI agents—significantly enhancing platform scalability, onboarding speed, and enterprise adoption.",
    "tags": [
      "AI Agents",
      "LLMs",
      "Adaptive Agents",
      "Backend Engineering",
      "FastAPI",
      "Python",
      "Integrations",
      "Webhooks",
      "Universal Parser",
      "Agent Templates",
      "Azure Metering",
      "Microsoft Marketplace",
      "Credit-Based Billing",
      "Subscription Billing",
      "iOS Monetization"
    ]
  },
  {
    "id": 2,
    "period": "Dec 2023 – May 2024",
    "isCurrent": false,
    "position": "Developer Intern",
    "company": "Linx Works (apiplatform.io)",
    "location": "Bangalore, Karnataka, India",
    "description": "Developed intelligent systems for an AI-powered conversational analytics assistant. Built NLP → SQL pipelines using transformer models, abstracted multi-dialect SQL execution, and improved query accuracy through iterative customer feedback loops. Enabled real-time data visualization through dynamic charting pipelines integrated into web and mobile applications.",
    "tags": [
      "NLP",
      "LLMs",
      "SQL Generation",
      "Transformer Models",
      "Natural Language Interfaces",
      "Python",
      "Backend Development",
      "Analytics Assistant",
      "Multi-dialect SQL",
      "Query Execution Engine",
      "Data Pipelines",
      "Chart.js",
      "D3.js",
      "Highcharts",
      "Real-time Visualization"]
  },
  {
    "id": 3,
    "period": "June 2022 – Dec 2022",
    "isCurrent": false,
    "position": "Data Analyst Intern",
    "company": "Saks Off 5th",
    "location": "Bangalore, Karnataka, India",
    "description": "Executed customer analytics projects focusing on segmentation, conversion funnel insights, and churn prediction. Built behavioral cohorts using clustering + RFM, improving targeting effectiveness. Designed attrition models and early-warning KPIs to reduce churn. Identified UX opportunities that improved session time by 19% and strengthened retention strategies across lifecycle campaigns.",
    "tags": [
      "Customer Segmentation",
      "RFM Analysis",
      "Clustering",
      "Conversion Funnel Analysis",
      "Churn Prediction",
      "Retention Analytics",
      "Behavioral Insights",
      "KPI Design",
      "Attrition Modeling",
      "E-commerce Analytics",
      "UX Analytics",
      "Lifecycle Campaigns",
      "Engagement Metrics"
    ]
  }
],
  contact: {
    location: "Tamil Nadu, India",
    email: "iam.suriyakanth@gmail.com",
    phone: "+91 98405 81941"
  }
};
